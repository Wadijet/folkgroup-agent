package logger

import (
	"fmt"
	"io"
	"os"
	"path/filepath"
	"runtime"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/sirupsen/logrus"
	"gopkg.in/natefinch/lumberjack.v2"
)

// LogLevel ƒë·ªãnh nghƒ©a c√°c m·ª©c log
type LogLevel string

const (
	LogLevelDebug LogLevel = "debug"
	LogLevelInfo  LogLevel = "info"
	LogLevelWarn  LogLevel = "warn"
	LogLevelError LogLevel = "error"
	LogLevelFatal LogLevel = "fatal"
)

// LogFormat ƒë·ªãnh nghƒ©a format c·ªßa log
type LogFormat string

const (
	LogFormatJSON LogFormat = "json" // JSON format cho production
	LogFormatText LogFormat = "text" // Text format cho development
)

// Config ch·ª©a c·∫•u h√¨nh cho logger
type Config struct {
	// LogLevel: debug, info, warn, error, fatal (m·∫∑c ƒë·ªãnh: info)
	Level string

	// LogFormat: json ho·∫∑c text (m·∫∑c ƒë·ªãnh: text)
	Format string

	// LogDir: Th∆∞ m·ª•c l∆∞u log files (m·∫∑c ƒë·ªãnh: ./logs)
	LogDir string

	// EnableConsole: B·∫≠t/t·∫Øt log ra console (m·∫∑c ƒë·ªãnh: true)
	EnableConsole string

	// EnableFile: B·∫≠t/t·∫Øt log ra file (m·∫∑c ƒë·ªãnh: true)
	EnableFile string

	// MaxSize: K√≠ch th∆∞·ªõc t·ªëi ƒëa c·ªßa log file tr∆∞·ªõc khi rotate (MB) (m·∫∑c ƒë·ªãnh: 100)
	MaxSize string

	// MaxBackups: S·ªë l∆∞·ª£ng log files c≈© ƒë∆∞·ª£c gi·ªØ l·∫°i (m·∫∑c ƒë·ªãnh: 10)
	MaxBackups string

	// MaxAge: S·ªë ng√†y gi·ªØ log files c≈© (m·∫∑c ƒë·ªãnh: 30)
	MaxAge string

	// Compress: N√©n log files c≈© (m·∫∑c ƒë·ªãnh: true)
	Compress string

	// EnableCaller: Hi·ªÉn th·ªã th√¥ng tin caller (file:line) (m·∫∑c ƒë·ªãnh: true)
	EnableCaller string
}

// NewConfig t·∫°o config m·ªõi t·ª´ environment variables v·ªõi default values
func NewConfig() *Config {
	return &Config{
		Level:         getEnv("LOG_LEVEL", "info"),
		Format:        getEnv("LOG_FORMAT", "text"),
		LogDir:        getEnv("LOG_DIR", "./logs"),
		EnableConsole: getEnv("LOG_ENABLE_CONSOLE", "true"),
		EnableFile:    getEnv("LOG_ENABLE_FILE", "true"),
		MaxSize:       getEnv("LOG_MAX_SIZE", "100"),
		MaxBackups:    getEnv("LOG_MAX_BACKUPS", "10"),
		MaxAge:        getEnv("LOG_MAX_AGE", "30"),
		Compress:      getEnv("LOG_COMPRESS", "true"),
		EnableCaller:  getEnv("LOG_ENABLE_CALLER", "true"),
	}
}

// getEnv l·∫•y gi√° tr·ªã t·ª´ environment variable, n·∫øu kh√¥ng c√≥ th√¨ d√πng default
func getEnv(key, defaultValue string) string {
	if value := os.Getenv(key); value != "" {
		return value
	}
	return defaultValue
}

var (
	loggers   = make(map[string]*logrus.Logger)
	loggersMu sync.Mutex
	rootDir   string
	globalCfg *Config
)

// InitLogger kh·ªüi t·∫°o logger v·ªõi c·∫•u h√¨nh
func InitLogger(cfg *Config) error {
	if cfg == nil {
		cfg = &Config{}
	}
	globalCfg = cfg
	return nil
}

// getRootDir l·∫•y root directory c·ªßa project
func getRootDir() string {
	if rootDir != "" {
		return rootDir
	}
	executable, err := os.Executable()
	if err != nil {
		// Fallback v·ªÅ th∆∞ m·ª•c hi·ªán t·∫°i
		wd, _ := os.Getwd()
		rootDir = wd
		return rootDir
	}
	rootDir = filepath.Dir(executable)
	return rootDir
}

// parseLogLevel chuy·ªÉn ƒë·ªïi string sang logrus.Level
func parseLogLevel(level string) logrus.Level {
	switch strings.ToLower(level) {
	case "debug":
		return logrus.DebugLevel
	case "info":
		return logrus.InfoLevel
	case "warn", "warning":
		return logrus.WarnLevel
	case "error":
		return logrus.ErrorLevel
	case "fatal":
		return logrus.FatalLevel
	default:
		return logrus.InfoLevel
	}
}

// parseBool chuy·ªÉn ƒë·ªïi string sang bool
func parseBool(s string, defaultValue bool) bool {
	if s == "" {
		return defaultValue
	}
	s = strings.ToLower(s)
	return s == "true" || s == "1" || s == "yes" || s == "on"
}

// parseInt chuy·ªÉn ƒë·ªïi string sang int
func parseInt(s string, defaultValue int) int {
	if s == "" {
		return defaultValue
	}
	result, err := strconv.Atoi(s)
	if err != nil {
		return defaultValue
	}
	return result
}

// CustomTextFormatter l√† formatter t√πy ch·ªânh ƒë·ªÉ l√†m n·ªïi b·∫≠t log l·ªói
type CustomTextFormatter struct {
	logrus.TextFormatter
}

// Format ƒë·ªãnh d·∫°ng log entry v·ªõi prefix ƒë·∫∑c bi·ªát cho ERROR v√† FATAL
// Gi·ªØ nguy√™n m√†u s·∫Øc c·ªßa logrus b·∫±ng c√°ch th√™m prefix v√†o ƒë·∫ßu (s·∫Ω c√≥ m√†u c·ªßa level)
func (f *CustomTextFormatter) Format(entry *logrus.Entry) ([]byte, error) {
	// G·ªçi formatter g·ªëc ƒë·ªÉ l·∫•y format chu·∫©n (ƒë√£ c√≥ color codes)
	data, err := f.TextFormatter.Format(entry)
	if err != nil {
		return nil, err
	}

	// N·∫øu l√† ERROR ho·∫∑c FATAL, th√™m prefix n·ªïi b·∫≠t v√†o ƒë·∫ßu d√≤ng
	if entry.Level == logrus.ErrorLevel || entry.Level == logrus.FatalLevel {
		var prefix string
		if entry.Level == logrus.ErrorLevel {
			prefix = "üö® [ERROR] "
		} else {
			prefix = "üíÄ [FATAL] "
		}

		// Th√™m prefix v√†o ƒë·∫ßu d√≤ng (s·∫Ω c√≥ m√†u ƒë·ªè t·ª´ logrus)
		result := append([]byte(prefix), data...)

		// Th√™m d√≤ng separator ·ªü cu·ªëi (lo·∫°i b·ªè newline cu·ªëi c√πng tr∆∞·ªõc)
		if len(result) > 0 && result[len(result)-1] == '\n' {
			result = result[:len(result)-1]
		}
		// Th√™m separator (s·∫Ω c√≥ m√†u t·ª´ logrus n·∫øu ƒëang d√πng m√†u)
		separator := "\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
		result = append(result, []byte(separator)...)

		return result, nil
	}

	// V·ªõi WARN, th√™m prefix nh·∫π h∆°n v√†o ƒë·∫ßu d√≤ng
	if entry.Level == logrus.WarnLevel {
		prefix := "‚ö†Ô∏è  [WARN] "
		result := append([]byte(prefix), data...)
		return result, nil
	}

	return data, nil
}

// createFormatter t·∫°o formatter d·ª±a tr√™n config
func createFormatter(format string) logrus.Formatter {
	if strings.ToLower(format) == "json" {
		return &logrus.JSONFormatter{
			TimestampFormat: time.RFC3339Nano,
			FieldMap: logrus.FieldMap{
				logrus.FieldKeyTime:  "timestamp",
				logrus.FieldKeyLevel: "level",
				logrus.FieldKeyMsg:   "message",
				logrus.FieldKeyFunc:  "caller",
			},
		}
	}

	// Custom text formatter v·ªõi m√†u s·∫Øc cho console v√† prefix ƒë·∫∑c bi·ªát cho l·ªói
	return &CustomTextFormatter{
		TextFormatter: logrus.TextFormatter{
			FullTimestamp:   true,
			TimestampFormat: "2006-01-02 15:04:05.000",
			ForceColors:     true,
			DisableColors:   false,
			CallerPrettyfier: func(f *runtime.Frame) (string, string) {
				s := strings.Split(f.Function, ".")
				funcName := s[len(s)-1]
				file := fmt.Sprintf("%s:%d", filepath.Base(f.File), f.Line)
				return funcName, file
			},
		},
	}
}

// GetLogger tr·∫£ v·ªÅ logger theo t√™n (app, jobs, ...)
// M·ªói logger s·∫Ω c√≥ file log ri√™ng
func GetLogger(name string) *logrus.Logger {
	loggersMu.Lock()
	defer loggersMu.Unlock()

	if logger, ok := loggers[name]; ok {
		return logger
	}

	// T·∫°o logger m·ªõi
	logger := logrus.New()

	// C·∫•u h√¨nh level
	cfg := globalCfg
	if cfg == nil {
		cfg = &Config{}
	}
	logger.SetLevel(parseLogLevel(cfg.Level))

	// C·∫•u h√¨nh formatter
	logger.SetFormatter(createFormatter(cfg.Format))

	// C·∫•u h√¨nh caller
	if parseBool(cfg.EnableCaller, true) {
		logger.SetReportCaller(true)
	}

	// T·∫°o writers
	var writers []io.Writer

	// Console writer
	if parseBool(cfg.EnableConsole, true) {
		writers = append(writers, os.Stdout)
	}

	// File writer v·ªõi rotation
	if parseBool(cfg.EnableFile, true) {
		logDir := cfg.LogDir
		if logDir == "" || logDir == "./logs" {
			logDir = filepath.Join(getRootDir(), "logs")
		}

		// ƒê·∫£m b·∫£o th∆∞ m·ª•c logs t·ªìn t·∫°i
		if err := os.MkdirAll(logDir, 0755); err != nil {
			panic(fmt.Sprintf("Kh√¥ng th·ªÉ t·∫°o th∆∞ m·ª•c logs t·∫°i %s: %v", logDir, err))
		}

		logFile := filepath.Join(logDir, fmt.Sprintf("%s.log", name))

		// C·∫•u h√¨nh log rotation
		fileWriter := &lumberjack.Logger{
			Filename:   logFile,
			MaxSize:    parseInt(cfg.MaxSize, 100), // MB
			MaxBackups: parseInt(cfg.MaxBackups, 10),
			MaxAge:     parseInt(cfg.MaxAge, 30), // days
			Compress:   parseBool(cfg.Compress, true),
			LocalTime:  true,
		}

		writers = append(writers, fileWriter)
	}

	// Set output
	if len(writers) > 0 {
		if len(writers) == 1 {
			logger.SetOutput(writers[0])
		} else {
			logger.SetOutput(io.MultiWriter(writers...))
		}
	}

	// Log th√¥ng tin kh·ªüi t·∫°o
	logger.WithFields(logrus.Fields{
		"logger_name": name,
		"level":       logger.GetLevel().String(),
		"format":      cfg.Format,
		"console":     parseBool(cfg.EnableConsole, true),
		"file":        parseBool(cfg.EnableFile, true),
	}).Info("Logger ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng")

	loggers[name] = logger
	return logger
}

// GetJobLogger tr·∫£ v·ªÅ logger cho jobs
func GetJobLogger() *logrus.Logger {
	return GetLogger("job")
}

// GetAppLogger tr·∫£ v·ªÅ logger cho application
func GetAppLogger() *logrus.Logger {
	return GetLogger("app")
}

// GetDefaultLogger tr·∫£ v·ªÅ logger m·∫∑c ƒë·ªãnh
func GetDefaultLogger() *logrus.Logger {
	return GetLogger("default")
}

// WithContext t·∫°o logger entry v·ªõi context fields
// S·ª≠ d·ª•ng ƒë·ªÉ th√™m trace ID, request ID, job ID, etc.
func WithContext(logger *logrus.Logger, fields map[string]interface{}) *logrus.Entry {
	return logger.WithFields(logrus.Fields(fields))
}

// WithTraceID t·∫°o logger entry v·ªõi trace ID
func WithTraceID(logger *logrus.Logger, traceID string) *logrus.Entry {
	return logger.WithField("trace_id", traceID)
}

// WithJobID t·∫°o logger entry v·ªõi job ID
func WithJobID(logger *logrus.Logger, jobID string) *logrus.Entry {
	return logger.WithField("job_id", jobID)
}

// WithRequestID t·∫°o logger entry v·ªõi request ID
func WithRequestID(logger *logrus.Logger, requestID string) *logrus.Entry {
	return logger.WithField("request_id", requestID)
}

// LogDuration log th·ªùi gian th·ª±c thi c·ªßa m·ªôt function
func LogDuration(logger *logrus.Entry, operation string, startTime time.Time) {
	duration := time.Since(startTime)
	logger.WithFields(logrus.Fields{
		"operation":   operation,
		"duration":    duration.String(),
		"duration_ms": duration.Milliseconds(),
	}).Debug("Operation completed")
}

// LogError log l·ªói v·ªõi stack trace
func LogError(logger *logrus.Entry, err error, message string, fields ...map[string]interface{}) {
	entry := logger.WithError(err)

	// Th√™m c√°c fields b·ªï sung
	for _, f := range fields {
		for k, v := range f {
			entry = entry.WithField(k, v)
		}
	}

	entry.Error(message)
}

// LogPanic log panic v√† recover
func LogPanic(logger *logrus.Logger) {
	if r := recover(); r != nil {
		logger.WithFields(logrus.Fields{
			"panic": r,
		}).Error("Panic recovered")
		panic(r) // Re-panic ƒë·ªÉ stack trace ƒë∆∞·ª£c hi·ªÉn th·ªã
	}
}

// CleanupOldLogs x√≥a c√°c log files c≈© d·ª±a tr√™n MaxAge v√† MaxBackups
// H√†m n√†y n√™n ƒë∆∞·ª£c g·ªçi ƒë·ªãnh k·ª≥ (v√≠ d·ª•: m·ªói ng√†y) ƒë·ªÉ ƒë·∫£m b·∫£o log c≈© ƒë∆∞·ª£c x√≥a
// ngay c·∫£ khi ch∆∞a ƒë·∫°t MaxSize (lumberjack ch·ªâ cleanup khi rotate)
func CleanupOldLogs() error {
	cfg := globalCfg
	if cfg == nil {
		cfg = &Config{}
	}

	// Ch·ªâ cleanup n·∫øu file logging ƒë∆∞·ª£c b·∫≠t
	if !parseBool(cfg.EnableFile, true) {
		return nil
	}

	logDir := cfg.LogDir
	if logDir == "" || logDir == "./logs" {
		logDir = filepath.Join(getRootDir(), "logs")
	}

	// Ki·ªÉm tra th∆∞ m·ª•c logs c√≥ t·ªìn t·∫°i kh√¥ng
	if _, err := os.Stat(logDir); os.IsNotExist(err) {
		return nil // Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i, kh√¥ng c·∫ßn cleanup
	}

	maxAge := parseInt(cfg.MaxAge, 30)
	maxBackups := parseInt(cfg.MaxBackups, 10)
	cutoffTime := time.Now().AddDate(0, 0, -maxAge)

	// ƒê·ªçc t·∫•t c·∫£ files trong th∆∞ m·ª•c logs
	files, err := os.ReadDir(logDir)
	if err != nil {
		return fmt.Errorf("kh√¥ng th·ªÉ ƒë·ªçc th∆∞ m·ª•c logs: %v", err)
	}

	// Nh√≥m c√°c log files theo logger name (v√≠ d·ª•: app.log, app.log.2024-01-01.gz, job.log, ...)
	logFilesByLogger := make(map[string][]logFileInfo)

	for _, file := range files {
		if file.IsDir() {
			continue
		}

		fileName := file.Name()
		filePath := filepath.Join(logDir, fileName)

		// L·∫•y th√¥ng tin file
		info, err := file.Info()
		if err != nil {
			continue
		}

		// X√°c ƒë·ªãnh logger name t·ª´ t√™n file
		// Format: {logger}.log ho·∫∑c {logger}.log.{timestamp}.gz
		loggerName := extractLoggerName(fileName)
		if loggerName == "" {
			continue // Kh√¥ng ph·∫£i log file
		}

		// Th√™m v√†o danh s√°ch
		if _, ok := logFilesByLogger[loggerName]; !ok {
			logFilesByLogger[loggerName] = make([]logFileInfo, 0)
		}

		logFilesByLogger[loggerName] = append(logFilesByLogger[loggerName], logFileInfo{
			path:    filePath,
			name:    fileName,
			modTime: info.ModTime(),
			size:    info.Size(),
		})
	}

	// Cleanup cho t·ª´ng logger
	totalDeleted := 0
	totalSizeFreed := int64(0)
	totalErrors := 0

	// L·∫•y logger ƒë·ªÉ log l·ªói
	appLogger := GetAppLogger()

	for loggerName, files := range logFilesByLogger {
		deleted, sizeFreed, errors := cleanupLoggerLogs(appLogger, loggerName, files, cutoffTime, maxBackups)
		totalDeleted += deleted
		totalSizeFreed += sizeFreed
		totalErrors += errors
	}

	// Log k·∫øt qu·∫£ (lu√¥n log ƒë·ªÉ bi·∫øt cleanup ƒë√£ ch·∫°y)

	// ƒê·∫øm t·ªïng s·ªë log files tr∆∞·ªõc khi cleanup
	totalLogFiles := 0
	for _, files := range logFilesByLogger {
		totalLogFiles += len(files)
	}

	if totalDeleted > 0 {
		appLogger.WithFields(logrus.Fields{
			"deleted_files":   totalDeleted,
			"size_freed_mb":   float64(totalSizeFreed) / 1024 / 1024,
			"max_age_days":    maxAge,
			"max_backups":     maxBackups,
			"total_files":     totalLogFiles,
			"remaining_files": totalLogFiles - totalDeleted,
			"delete_errors":   totalErrors,
		}).Info("üßπ ƒê√£ cleanup log files c≈©")
	} else {
		fields := logrus.Fields{
			"max_age_days":    maxAge,
			"max_backups":     maxBackups,
			"log_dir":         logDir,
			"total_log_files": totalLogFiles,
		}
		if totalErrors > 0 {
			fields["delete_errors"] = totalErrors
			appLogger.WithFields(fields).Warn("üßπ Cleanup log: Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c x√≥a, nh∆∞ng c√≥ l·ªói khi x√≥a file")
		} else {
			appLogger.WithFields(fields).Info("üßπ Cleanup log: Kh√¥ng c√≥ file n√†o c·∫ßn x√≥a (t·∫•t c·∫£ files ƒë·ªÅu c√≤n trong th·ªùi h·∫°n)")
		}
	}

	return nil
}

// logFileInfo ch·ª©a th√¥ng tin v·ªÅ m·ªôt log file
type logFileInfo struct {
	path    string
	name    string
	modTime time.Time
	size    int64
}

// extractLoggerName tr√≠ch xu·∫•t t√™n logger t·ª´ t√™n file
// V√≠ d·ª•: "app.log" -> "app", "app.log.2024-01-01.gz" -> "app"
func extractLoggerName(fileName string) string {
	// Lo·∫°i b·ªè extension .gz n·∫øu c√≥
	fileName = strings.TrimSuffix(fileName, ".gz")

	// T√°ch theo d·∫•u ch·∫•m
	parts := strings.Split(fileName, ".")
	if len(parts) < 2 {
		return ""
	}

	// Format c·ªßa lumberjack: {logger}.log ho·∫∑c {logger}.log.{timestamp}
	// T√¨m ph·∫ßn "log" trong t√™n file
	for i, part := range parts {
		if part == "log" {
			// L·∫•y t·∫•t c·∫£ ph·∫ßn tr∆∞·ªõc "log" l√†m logger name
			if i > 0 {
				return strings.Join(parts[:i], ".")
			}
			return ""
		}
	}

	return ""
}

// cleanupLoggerLogs cleanup log files cho m·ªôt logger c·ª• th·ªÉ
// Tr·∫£ v·ªÅ: s·ªë file ƒë√£ x√≥a, t·ªïng dung l∆∞·ª£ng ƒë√£ gi·∫£i ph√≥ng, s·ªë l·ªói khi x√≥a
func cleanupLoggerLogs(logger *logrus.Logger, loggerName string, files []logFileInfo, cutoffTime time.Time, maxBackups int) (deleted int, sizeFreed int64, errors int) {
	// T√°ch c√°c file backup (b·ªè qua file hi·ªán t·∫°i v√¨ n√≥ ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng)
	var backupFiles []logFileInfo

	expectedCurrentFile := loggerName + ".log"

	for i := range files {
		// B·ªè qua file hi·ªán t·∫°i (ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng)
		if files[i].name == expectedCurrentFile {
			continue
		}
		// File backup c√≥ format: {logger}.log.{timestamp} ho·∫∑c {logger}.log.{timestamp}.gz
		if strings.HasPrefix(files[i].name, expectedCurrentFile+".") {
			backupFiles = append(backupFiles, files[i])
		}
	}

	// S·∫Øp x·∫øp backup files theo th·ªùi gian (m·ªõi nh·∫•t tr∆∞·ªõc)
	sortLogFilesByTime(backupFiles)

	// X√≥a c√°c file c≈© h∆°n cutoffTime
	for _, file := range backupFiles {
		if file.modTime.Before(cutoffTime) {
			if err := os.Remove(file.path); err == nil {
				deleted++
				sizeFreed += file.size
			} else {
				// Log l·ªói chi ti·∫øt khi x√≥a file th·∫•t b·∫°i (quan tr·ªçng cho Linux)
				errors++
				logger.WithFields(logrus.Fields{
					"file_path": file.path,
					"file_name": file.name,
					"error":     err.Error(),
					"mod_time":  file.modTime.Format(time.RFC3339),
				}).Error("‚ùå Kh√¥ng th·ªÉ x√≥a log file c≈© (c√≥ th·ªÉ do quy·ªÅn truy c·∫≠p tr√™n Linux)")
			}
		}
	}

	// Gi·ªØ ch·ªâ maxBackups files m·ªõi nh·∫•t (sau khi ƒë√£ x√≥a theo MaxAge)
	// X√≥a c√°c file v∆∞·ª£t qu√° maxBackups
	if len(backupFiles) > maxBackups {
		// ƒê√£ s·∫Øp x·∫øp, l·∫•y c√°c file t·ª´ maxBackups tr·ªü ƒëi
		for i := maxBackups; i < len(backupFiles); i++ {
			// Ch·ªâ x√≥a n·∫øu ch∆∞a b·ªã x√≥a b·ªüi MaxAge
			if !backupFiles[i].modTime.Before(cutoffTime) {
				if err := os.Remove(backupFiles[i].path); err == nil {
					deleted++
					sizeFreed += backupFiles[i].size
				} else {
					// Log l·ªói chi ti·∫øt khi x√≥a file th·∫•t b·∫°i (quan tr·ªçng cho Linux)
					errors++
					logger.WithFields(logrus.Fields{
						"file_path": backupFiles[i].path,
						"file_name": backupFiles[i].name,
						"error":     err.Error(),
						"mod_time":  backupFiles[i].modTime.Format(time.RFC3339),
					}).Error("‚ùå Kh√¥ng th·ªÉ x√≥a log file c≈© (c√≥ th·ªÉ do quy·ªÅn truy c·∫≠p tr√™n Linux)")
				}
			}
		}
	}

	return deleted, sizeFreed, errors
}

// hasTimestamp ki·ªÉm tra xem t√™n file c√≥ ch·ª©a timestamp kh√¥ng
func hasTimestamp(fileName string) bool {
	// Timestamp th∆∞·ªùng c√≥ format: YYYY-MM-DD ho·∫∑c YYYYMMDD
	// Ki·ªÉm tra pattern: .log.YYYY-MM-DD ho·∫∑c .log.YYYYMMDD
	parts := strings.Split(fileName, ".")
	if len(parts) < 3 {
		return false
	}

	// Ph·∫ßn cu·ªëi c√πng (tr∆∞·ªõc .gz n·∫øu c√≥) c√≥ th·ªÉ l√† timestamp
	lastPart := parts[len(parts)-1]
	if strings.HasSuffix(fileName, ".gz") {
		lastPart = parts[len(parts)-2]
	}

	// Ki·ªÉm tra format YYYY-MM-DD ho·∫∑c YYYYMMDD
	if len(lastPart) == 10 && strings.Count(lastPart, "-") == 2 {
		return true // Format: YYYY-MM-DD
	}
	if len(lastPart) == 8 {
		// C√≥ th·ªÉ l√† YYYYMMDD
		return true
	}

	return false
}

// sortLogFilesByTime s·∫Øp x·∫øp log files theo th·ªùi gian (m·ªõi nh·∫•t tr∆∞·ªõc)
func sortLogFilesByTime(files []logFileInfo) {
	for i := 0; i < len(files)-1; i++ {
		for j := i + 1; j < len(files); j++ {
			if files[i].modTime.Before(files[j].modTime) {
				files[i], files[j] = files[j], files[i]
			}
		}
	}
}

// StartLogCleanupScheduler kh·ªüi ƒë·ªông scheduler ƒë·ªÉ cleanup log ƒë·ªãnh k·ª≥
// interval: kho·∫£ng th·ªùi gian gi·ªØa c√°c l·∫ßn cleanup (v√≠ d·ª•: 24 * time.Hour)
func StartLogCleanupScheduler(interval time.Duration) {
	appLogger := GetAppLogger()
	appLogger.WithFields(logrus.Fields{
		"interval_hours": interval.Hours(),
		"interval":       interval.String(),
	}).Info("üîÑ Kh·ªüi ƒë·ªông log cleanup scheduler")

	go func() {
		ticker := time.NewTicker(interval)
		defer ticker.Stop()

		// Ch·∫°y cleanup ngay l·∫≠p t·ª©c l·∫ßn ƒë·∫ßu
		appLogger.Info("üßπ Ch·∫°y cleanup log l·∫ßn ƒë·∫ßu...")
		if err := CleanupOldLogs(); err != nil {
			appLogger.WithError(err).Error("‚ùå L·ªói khi cleanup log files")
		} else {
			appLogger.Info("‚úÖ Cleanup log l·∫ßn ƒë·∫ßu ho√†n t·∫•t")
		}

		// Sau ƒë√≥ ch·∫°y ƒë·ªãnh k·ª≥
		for range ticker.C {
			appLogger.Info("üßπ Ch·∫°y cleanup log ƒë·ªãnh k·ª≥...")
			if err := CleanupOldLogs(); err != nil {
				appLogger.WithError(err).Error("‚ùå L·ªói khi cleanup log files")
			} else {
				appLogger.Info("‚úÖ Cleanup log ƒë·ªãnh k·ª≥ ho√†n t·∫•t")
			}
		}
	}()
}
